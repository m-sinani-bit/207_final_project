{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":413.225324,"end_time":"2024-04-04T20:45:20.092418","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-04T20:38:26.867094","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0b444c7dbe784eecbd677fc928263d6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0bfd2faad521416badbaf82ba958b5e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_14012c2a9d694085a5de7bc18181c8f2","max":11138,"min":0,"orientation":"horizontal","style":"IPY_MODEL_890d04656def475bbecba04bd08e510a","value":11138}},"14012c2a9d694085a5de7bc18181c8f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"285830a3fedc46ae9016eaf4d5cbb65b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c70b052f3584789a8ada709eab6e971":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d0f882f7bec42d4917e403a75117643","placeholder":"​","style":"IPY_MODEL_5e7b7e33731b4e1ebee10e92e0f6cddd","value":"100%"}},"388eb60040f843df81288df2a20c5047":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_47af34858c15417393e8666408c12630","placeholder":"​","style":"IPY_MODEL_d6e97d51e00648c2beb5f9731a394b25","value":" 1/1 [00:00&lt;00:00, 76.33it/s]"}},"3f13d08062824818a26070b753043e45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_534029093e614865bd49e92cf36f6783","IPY_MODEL_85d94aa1fd1f49aba6880fd8fdc3b405","IPY_MODEL_388eb60040f843df81288df2a20c5047"],"layout":"IPY_MODEL_f7b93335db284a3e9c547ee17fcef09d"}},"47af34858c15417393e8666408c12630":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"534029093e614865bd49e92cf36f6783":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_285830a3fedc46ae9016eaf4d5cbb65b","placeholder":"​","style":"IPY_MODEL_c0230a11b1264c10914d43e92172665c","value":"100%"}},"5e7b7e33731b4e1ebee10e92e0f6cddd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6658647e3cb04aa1babef0254aab3f59":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d074a5222fc4311be98aebbfb0498da":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80541724f5da49cd879e38f67d55bcf9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c70b052f3584789a8ada709eab6e971","IPY_MODEL_0bfd2faad521416badbaf82ba958b5e5","IPY_MODEL_911b8373a1d14ad88f1fd67330800dc5"],"layout":"IPY_MODEL_c56686498f6844f69eefb0af5db266c3"}},"85d94aa1fd1f49aba6880fd8fdc3b405":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d074a5222fc4311be98aebbfb0498da","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b444c7dbe784eecbd677fc928263d6b","value":1}},"890d04656def475bbecba04bd08e510a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"911b8373a1d14ad88f1fd67330800dc5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c69d7ce253f44916b7e6624430e811bf","placeholder":"​","style":"IPY_MODEL_6658647e3cb04aa1babef0254aab3f59","value":" 11138/11138 [02:57&lt;00:00, 66.07it/s]"}},"9d0f882f7bec42d4917e403a75117643":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0230a11b1264c10914d43e92172665c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c56686498f6844f69eefb0af5db266c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c69d7ce253f44916b7e6624430e811bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6e97d51e00648c2beb5f9731a394b25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7b93335db284a3e9c547ee17fcef09d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\" # you can also use tensorflow or torch\n\nimport keras_cv\nimport keras\nfrom keras import ops\nimport tensorflow as tf\n\nimport cv2\nimport pandas as pd\nimport numpy as np\nfrom glob import glob\nfrom tqdm.notebook import tqdm\nimport joblib\n\nimport matplotlib.pyplot as plt ","metadata":{"papermill":{"duration":17.606024,"end_time":"2024-04-04T20:38:47.317288","exception":false,"start_time":"2024-04-04T20:38:29.711264","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"TensorFlow:\", tf.__version__)\nprint(\"Keras:\", keras.__version__)\nprint(\"KerasCV:\", keras_cv.__version__)","metadata":{"papermill":{"duration":0.01477,"end_time":"2024-04-04T20:38:47.339028","exception":false,"start_time":"2024-04-04T20:38:47.324258","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    verbose = 1  # Verbosity\n    seed = 42  # Random seed\n    preset = \"efficientnetv2_b2_imagenet\"  # Name of pretrained classifier\n    image_size = [400, 300]  # Input image size\n    epochs = 10 # Training epochs\n    batch_size = 64  # Batch size\n    lr_mode = \"cos\" # LR scheduler mode from one of \"cos\", \"step\", \"exp\"\n    drop_remainder = True  # Drop incomplete batches\n    num_classes = 1 # Number of classes in the dataset\n    fold = 0 # Which fold to set as validation data\n    class_names = ['Seizure']\n    label2name = dict(enumerate(class_names))\n    name2label = {v:k for k, v in label2name.items()}","metadata":{"papermill":{"duration":0.014801,"end_time":"2024-04-04T20:38:47.360261","exception":false,"start_time":"2024-04-04T20:38:47.345460","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.set_random_seed(CFG.seed)","metadata":{"papermill":{"duration":0.013553,"end_time":"2024-04-04T20:38:47.380306","exception":false,"start_time":"2024-04-04T20:38:47.366753","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load in data","metadata":{"papermill":{"duration":0.006307,"end_time":"2024-04-04T20:38:47.393003","exception":false,"start_time":"2024-04-04T20:38:47.386696","status":"completed"},"tags":[]}},{"cell_type":"code","source":"BASE_PATH = \"/kaggle/input/hms-harmful-brain-activity-classification\"\n\nSPEC_DIR = \"/tmp/dataset/hms-hbac\"\nos.makedirs(SPEC_DIR+'/train_spectrograms', exist_ok=True)\nos.makedirs(SPEC_DIR+'/test_spectrograms', exist_ok=True)","metadata":{"papermill":{"duration":0.013792,"end_time":"2024-04-04T20:38:47.413346","exception":false,"start_time":"2024-04-04T20:38:47.399554","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train + Valid\ndf = pd.read_csv(f'{BASE_PATH}/train.csv')\ndf['eeg_path'] = f'{BASE_PATH}/train_eegs/'+df['eeg_id'].astype(str)+'.parquet'\ndf['spec_path'] = f'{BASE_PATH}/train_spectrograms/'+df['spectrogram_id'].astype(str)+'.parquet'\ndf['spec2_path'] = f'{SPEC_DIR}/train_spectrograms/'+df['spectrogram_id'].astype(str)+'.npy'\ndf['class_name'] = df.expert_consensus.copy()\ndf['class_label'] = df.expert_consensus.map(CFG.name2label)\ndisplay(df.head(2))\n\n# Test\ntest_df = pd.read_csv(f'{BASE_PATH}/test.csv')\ntest_df['eeg_path'] = f'{BASE_PATH}/test_eegs/'+test_df['eeg_id'].astype(str)+'.parquet'\ntest_df['spec_path'] = f'{BASE_PATH}/test_spectrograms/'+test_df['spectrogram_id'].astype(str)+'.parquet'\ntest_df['spec2_path'] = f'{SPEC_DIR}/test_spectrograms/'+test_df['spectrogram_id'].astype(str)+'.npy'\ndisplay(test_df.head(2))","metadata":{"papermill":{"duration":0.559915,"end_time":"2024-04-04T20:38:47.979879","exception":false,"start_time":"2024-04-04T20:38:47.419964","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Set binary class label","metadata":{"papermill":{"duration":0.007812,"end_time":"2024-04-04T20:38:47.994823","exception":false,"start_time":"2024-04-04T20:38:47.987011","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df['seizure_binary'] = np.where(df.expert_consensus == 'Seizure',1,0)","metadata":{"papermill":{"duration":0.030702,"end_time":"2024-04-04T20:38:48.032324","exception":false,"start_time":"2024-04-04T20:38:48.001622","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.seizure_binary.value_counts()","metadata":{"papermill":{"duration":0.021589,"end_time":"2024-04-04T20:38:48.061096","exception":false,"start_time":"2024-04-04T20:38:48.039507","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create cross val splits","metadata":{"papermill":{"duration":0.007169,"end_time":"2024-04-04T20:38:48.075246","exception":false,"start_time":"2024-04-04T20:38:48.068077","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedGroupKFold\n\nsgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=CFG.seed)\n\ndf[\"fold\"] = -1\ndf.reset_index(drop=True, inplace=True)\nfor fold, (train_idx, valid_idx) in enumerate(\n    sgkf.split(df, y=df[\"seizure_binary\"], groups=df[\"patient_id\"])\n):\n    df.loc[valid_idx, \"fold\"] = fold\ndf.groupby([\"fold\", \"class_name\"])[[\"eeg_id\"]].count().T","metadata":{"papermill":{"duration":1.883912,"end_time":"2024-04-04T20:38:49.966117","exception":false,"start_time":"2024-04-04T20:38:48.082205","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data processing","metadata":{"papermill":{"duration":0.007826,"end_time":"2024-04-04T20:38:49.981715","exception":false,"start_time":"2024-04-04T20:38:49.973889","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Define a function to process a single eeg_id\ndef process_spec(spec_id, split=\"train\"):\n    spec_path = f\"{BASE_PATH}/{split}_spectrograms/{spec_id}.parquet\"\n    spec = pd.read_parquet(spec_path)\n    spec = spec.fillna(0).values[:, 1:].T # fill NaN values with 0, transpose for (Time, Freq) -> (Freq, Time)\n    spec = spec.astype(\"float32\")\n    np.save(f\"{SPEC_DIR}/{split}_spectrograms/{spec_id}.npy\", spec)\n\n# Get unique spec_ids of train and valid data\nspec_ids = df[\"spectrogram_id\"].unique()\n\n# Parallelize the processing using joblib for training data\n_ = joblib.Parallel(n_jobs=-1, backend=\"loky\")(\n    joblib.delayed(process_spec)(spec_id, \"train\")\n    for spec_id in tqdm(spec_ids, total=len(spec_ids))\n)\n\n# Get unique spec_ids of test data\ntest_spec_ids = test_df[\"spectrogram_id\"].unique()\n\n# Parallelize the processing using joblib for test data\n_ = joblib.Parallel(n_jobs=-1, backend=\"loky\")(\n    joblib.delayed(process_spec)(spec_id, \"test\")\n    for spec_id in tqdm(test_spec_ids, total=len(test_spec_ids))\n)","metadata":{"papermill":{"duration":177.706341,"end_time":"2024-04-04T20:41:47.695363","exception":false,"start_time":"2024-04-04T20:38:49.989022","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create augmenter (not used for now) and build dataset","metadata":{"papermill":{"duration":0.007592,"end_time":"2024-04-04T20:41:47.710938","exception":false,"start_time":"2024-04-04T20:41:47.703346","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def build_augmenter(dim=CFG.image_size):\n    augmenters = [\n        keras_cv.layers.MixUp(alpha=2.0),\n        keras_cv.layers.RandomCutout(height_factor=(1.0, 1.0),\n                                     width_factor=(0.06, 0.1)), # freq-masking\n        keras_cv.layers.RandomCutout(height_factor=(0.06, 0.1),\n                                     width_factor=(1.0, 1.0)), # time-masking\n    ]\n    \n    def augment(img, label):\n        data = {\"images\":img, \"labels\":label}\n        for augmenter in augmenters:\n            if tf.random.uniform([]) < 0.5:\n                data = augmenter(data, training=True)\n        return data[\"images\"], data[\"labels\"]\n    \n    return augment\n\n\ndef build_decoder(with_labels=True, target_size=CFG.image_size, dtype=32):\n    def decode_signal(path, offset=None):\n        # Read .npy files and process the signal\n        file_bytes = tf.io.read_file(path)\n        sig = tf.io.decode_raw(file_bytes, tf.float32)\n        sig = sig[1024//dtype:]  # Remove header tag\n        sig = tf.reshape(sig, [400, -1])\n        \n        # Extract labeled subsample from full spectrogram using \"offset\"\n        if offset is not None: \n            offset = offset // 2  # Only odd values are given\n            sig = sig[:, offset:offset+300]\n            \n            # Pad spectrogram to ensure the same input shape of [400, 300]\n            pad_size = tf.math.maximum(0, 300 - tf.shape(sig)[1])\n            sig = tf.pad(sig, [[0, 0], [0, pad_size]])\n            sig = tf.reshape(sig, [400, 300])\n        \n        # Log spectrogram \n        sig = tf.clip_by_value(sig, tf.math.exp(-4.0), tf.math.exp(8.0)) # avoid 0 in log\n        sig = tf.math.log(sig)\n        \n        # Normalize spectrogram\n        sig -= tf.math.reduce_mean(sig)\n        sig /= tf.math.reduce_std(sig) + 1e-6\n        \n        # Mono channel to 3 channels to use \"ImageNet\" weights\n        sig = tf.tile(sig[..., None], [1, 1, 3])\n        return sig\n    \n    def decode_label(label):\n        label = tf.one_hot(label, CFG.num_classes)\n        label = tf.cast(label, tf.float32)\n        label = tf.reshape(label, [CFG.num_classes])\n        return label\n    \n    def decode_with_labels(path, offset=None, label=None):\n        sig = decode_signal(path, offset)\n        label = decode_label(label)\n        return (sig, label)\n    \n    return decode_with_labels if with_labels else decode_signal\n\n\ndef build_dataset(paths, offsets=None, labels=None, batch_size=32, cache=True,\n                  decode_fn=None, augment_fn=None,\n                  augment=False, repeat=True, shuffle=1024, \n                  cache_dir=\"\", drop_remainder=False):\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n    \n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n    \n    if augment_fn is None:\n        augment_fn = build_augmenter()\n    \n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = (paths, offsets) if labels is None else (paths, offsets, labels)\n    \n    ds = tf.data.Dataset.from_tensor_slices(slices)\n    ds = ds.map(decode_fn, num_parallel_calls=AUTO)\n    ds = ds.cache(cache_dir) if cache else ds\n    ds = ds.repeat() if repeat else ds\n    if shuffle: \n        ds = ds.shuffle(shuffle, seed=CFG.seed)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n    ds = ds.map(augment_fn, num_parallel_calls=AUTO) if augment else ds\n    ds = ds.prefetch(AUTO)\n    return ds","metadata":{"papermill":{"duration":0.030807,"end_time":"2024-04-04T20:41:47.749545","exception":false,"start_time":"2024-04-04T20:41:47.718738","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df = df.groupby(\"spectrogram_id\").head(1).reset_index(drop=True)\ntrain_df = sample_df[sample_df.fold != CFG.fold]\nvalid_df = sample_df[sample_df.fold == CFG.fold]\nprint(f\"# Num Train: {len(train_df)} | Num Valid: {len(valid_df)}\")\n\n# Train\ntrain_paths = train_df.spec2_path.values\ntrain_offsets = train_df.spectrogram_label_offset_seconds.values.astype(int)\ntrain_labels = train_df.seizure_binary.values\ntrain_ds = build_dataset(train_paths, train_offsets, train_labels, batch_size=CFG.batch_size,\n                         repeat=True, shuffle=True, augment=True, cache=True)\n\n# Valid\nvalid_paths = valid_df.spec2_path.values\nvalid_offsets = valid_df.spectrogram_label_offset_seconds.values.astype(int)\nvalid_labels = valid_df.seizure_binary.values\nvalid_ds = build_dataset(valid_paths, valid_offsets, valid_labels, batch_size=CFG.batch_size,\n                         repeat=False, shuffle=False, augment=False, cache=True)","metadata":{"papermill":{"duration":3.179691,"end_time":"2024-04-04T20:41:50.936941","exception":false,"start_time":"2024-04-04T20:41:47.757250","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Start modeling","metadata":{"papermill":{"duration":0.007576,"end_time":"2024-04-04T20:41:50.952660","exception":false,"start_time":"2024-04-04T20:41:50.945084","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#baseline model: predict dominant class\naccuracies = []\nfor fold in df.fold.unique():\n    train = df[df.fold != fold]\n    val = df[df.fold == fold]\n    if np.mean(train.seizure_binary) >= 0.5:\n        pred = 1\n    else:\n        pred = 0\n    accuracy = sum(np.where(val.seizure_binary == pred,1,0))/len(val)\n    accuracies.append(accuracy)\nprint('crossval accuracies:',accuracies)\nprint('mean crossval accuracy:',np.mean(accuracies))","metadata":{"papermill":{"duration":0.173477,"end_time":"2024-04-04T20:41:51.133758","exception":false,"start_time":"2024-04-04T20:41:50.960281","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOSS = keras.losses.BinaryCrossentropy()","metadata":{"papermill":{"duration":0.014392,"end_time":"2024-04-04T20:41:51.156197","exception":false,"start_time":"2024-04-04T20:41:51.141805","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model 2: simple logistic regression\ntf.keras.backend.clear_session()\n\nmodel = keras.Sequential()\n\nmodel.add(keras.layers.Flatten())\n\nmodel.add(keras.layers.Dense(\n  units=1,                     \n  use_bias=True,               \n  activation=\"sigmoid\"         \n))\n\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n\nmodel.compile(loss='binary_crossentropy', \n            optimizer=optimizer, \n            metrics=[LOSS])","metadata":{"papermill":{"duration":0.034758,"end_time":"2024-04-04T20:41:51.198612","exception":false,"start_time":"2024-04-04T20:41:51.163854","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n  train_ds, \n  epochs=5,\n  steps_per_epoch=len(train_df)//CFG.batch_size,\n  validation_data=valid_ds, \n  verbose=CFG.verbose           \n  )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# history = model.fit(\n  train_ds, \n  epochs=5,\n  steps_per_epoch=len(train_df)//CFG.batch_size,\n  validation_data=valid_ds, \n  verbose=CFG.verbose           \n  )","metadata":{"papermill":{"duration":202.592411,"end_time":"2024-04-04T20:45:13.798828","exception":false,"start_time":"2024-04-04T20:41:51.206417","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-11T00:06:59.546113Z","iopub.execute_input":"2024-04-11T00:06:59.546958Z","iopub.status.idle":"2024-04-11T00:09:42.577555Z","shell.execute_reply.started":"2024-04-11T00:06:59.546919Z","shell.execute_reply":"2024-04-11T00:09:42.576725Z"}}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,f1_score\nval_preds = np.rint(model.predict(valid_ds))\n\nprint('val accuracy:',accuracy_score(valid_labels,val_preds))\nprint('val f1:',f1_score(valid_labels,val_preds))","metadata":{"papermill":{"duration":2.268367,"end_time":"2024-04-04T20:45:16.131684","exception":false,"start_time":"2024-04-04T20:45:13.863317","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####JAYLENE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, InputLayer\n\nmodel = Sequential([\n    InputLayer(shape=(CFG.image_size[0], CFG.image_size[1], 3)),  \n    Conv2D(16, kernel_size=(3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    BatchNormalization(),\n    \n    Conv2D(32, kernel_size=(3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    BatchNormalization(),\n    \n    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    BatchNormalization(),\n    \n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')  # For binary classification\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_ds,\n    validation_data=valid_ds,\n    epochs=CFG.epochs,\n    steps_per_epoch=len(train_df) // CFG.batch_size,\n    validation_steps=len(valid_df) // CFG.batch_size,\n    verbose=CFG.verbose\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = history.history\nx_arr = np.arange(len(hist['loss'])) + 1\n\nfig = plt.figure(figsize=(12, 4))\nax = fig.add_subplot(1, 2, 1)\nax.plot(x_arr, hist['loss'], '-o', label='Train loss')\nax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss')\nax.legend(fontsize=15)\nax.set_xlabel('Epoch', size=15)\nax.set_ylabel('Loss', size=15)\n\nax = fig.add_subplot(1, 2, 2)\nax.plot(x_arr, hist['accuracy'], '-o', label='Train acc.')\nax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation acc.')\nax.legend(fontsize=15)\nax.set_xlabel('Epoch', size=15)\nax.set_ylabel('Accuracy', size=15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\nval_predictions = model.predict(valid_ds, batch_size=32)\nval_predictions = np.round(val_predictions).astype(int)\n\n# True labels\ntrue_labels = valid_labels \n\nprint(classification_report(true_labels, val_predictions))\nprint(confusion_matrix(true_labels, val_predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import class_weight\nimport numpy as np\n\n# Calculate class weights\nclass_weights = class_weight.compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(train_labels),\n    y=train_labels)\nclass_weight_dict = dict(enumerate(class_weights))\n\n# Configure the model\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy'])\n\n# Train the model with class weights\nhistory = model.fit(\n    train_ds,\n    epochs=CFG.epochs,\n    steps_per_epoch=len(train_df) // CFG.batch_size,\n    validation_data=valid_ds,\n    validation_steps=len(valid_df) // CFG.batch_size,\n    class_weight=class_weight_dict,  \n    verbose=CFG.verbose)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = history.history\nx_arr = np.arange(len(hist['loss'])) + 1\n\nfig = plt.figure(figsize=(12, 4))\nax = fig.add_subplot(1, 2, 1)\nax.plot(x_arr, hist['loss'], '-o', label='Train loss')\nax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss')\nax.legend(fontsize=15)\nax.set_xlabel('Epoch', size=15)\nax.set_ylabel('Loss', size=15)\n\nax = fig.add_subplot(1, 2, 2)\nax.plot(x_arr, hist['accuracy'], '-o', label='Train acc.')\nax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation acc.')\nax.legend(fontsize=15)\nax.set_xlabel('Epoch', size=15)\nax.set_ylabel('Accuracy', size=15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATA AUGMENTAITONS**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndata_gen_args = {\n    'rotation_range': 20,  # degrees\n    'width_shift_range': 0.2,  # fraction of total width\n    'height_shift_range': 0.2,  # fraction of total height\n    'zoom_range': 0.2,\n    'horizontal_flip': True,\n    'vertical_flip': True,\n    'fill_mode': 'nearest'\n}\n\nimage_data_generator = ImageDataGenerator(**data_gen_args)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augment_image(image, label):\n    # Randomly flip the image horizontally\n    image = tf.image.random_flip_left_right(image)\n\n    # Randomly flip the image vertically\n    image = tf.image.random_flip_up_down(image)\n\n    # Randomly change the brightness of the image\n    image = tf.image.random_brightness(image, max_delta=0.1)\n\n    # Randomly change the contrast of the image\n    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n\n    image = tf.clip_by_value(image, 0.0, 1.0)\n    \n    return image, label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augmented_train_ds = train_ds.map(augment_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    augmented_train_ds,\n    validation_data=valid_ds,\n    epochs=CFG.epochs,\n    steps_per_epoch=len(train_df) // CFG.batch_size,\n    validation_steps=len(valid_df) // CFG.batch_size\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = history.history\nx_arr = np.arange(len(hist['loss'])) + 1\n\nfig = plt.figure(figsize=(12, 4))\nax = fig.add_subplot(1, 2, 1)\nax.plot(x_arr, hist['loss'], '-o', label='Train loss')\nax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss')\nax.legend(fontsize=15)\nax.set_xlabel('Epoch', size=15)\nax.set_ylabel('Loss', size=15)\n\nax = fig.add_subplot(1, 2, 2)\nax.plot(x_arr, hist['accuracy'], '-o', label='Train acc.')\nax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation acc.')\nax.legend(fontsize=15)\nax.set_xlabel('Epoch', size=15)\nax.set_ylabel('Accuracy', size=15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the entire validation dataset\nval_loss, val_accuracy = model.evaluate(valid_ds)\nprint(f\"Validation Loss: {val_loss}\")\nprint(f\"Validation Accuracy: {val_accuracy}\")\n\nfrom sklearn.metrics import classification_report\n\ny_true = np.concatenate([y for x, y in valid_ds], axis=0)\ny_pred = model.predict(valid_ds)\ny_pred = np.round(y_pred).astype(int)\n\nprint(classification_report(y_true, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\n\n# Define data augmentation function using TensorFlow ops\ndef augment_data(image, label):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_brightness(image, max_delta=0.1)\n    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n    return image, label\n\n# Apply the augmentation to the training dataset\naugmented_train_ds = train_ds.map(augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n\n# Visualize some augmented images\ndef plot_augmented_images(dataset):\n    plt.figure(figsize=(10, 10))\n    for images, _ in dataset.take(1):\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            plt.imshow(images[i].numpy().astype(\"uint8\"))\n            plt.axis(\"off\")\n    plt.show()\n\nplot_augmented_images(augmented_train_ds)\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Fit the model using the augmented dataset\nhistory = model.fit(\n    augmented_train_ds,\n    epochs=CFG.epochs,\n    validation_data=valid_ds,\n    steps_per_epoch=len(train_df) // CFG.batch_size,\n    validation_steps=len(valid_df) // CFG.batch_size\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = history.history\nx_arr = np.arange(len(hist['loss'])) + 1\n\nfig = plt.figure(figsize=(12, 4))\nax = fig.add_subplot(1, 2, 1)\nax.plot(x_arr, hist['loss'], '-o', label='Train loss')\nax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss')\nax.legend(fontsize=15)\nax.set_xlabel('Epoch', size=15)\nax.set_ylabel('Loss', size=15)\n\nax = fig.add_subplot(1, 2, 2)\nax.plot(x_arr, hist['accuracy'], '-o', label='Train acc.')\nax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation acc.')\nax.legend(fontsize=15)\nax.set_xlabel('Epoch', size=15)\nax.set_ylabel('Accuracy', size=15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Kam model","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Define the model\nmodel = Sequential([\n    InputLayer(shape=(CFG.image_size[0], CFG.image_size[1], 3)),  \n    Conv2D(16, kernel_size=(3, 3), strides=(1, 1), padding='same', data_format='channels_last', activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    BatchNormalization(),\n    \n    Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    BatchNormalization(),\n    \n    Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    BatchNormalization(),\n    \n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')  # For binary classification\n])\n\n# Compile the model with custom learning rate\noptimizer = Adam()  # Adjust the learning rate as needed\nmodel.compile(optimizer= optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n# Define early stopping to prevent overfitting\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n# Train the model with data augmentation and early stopping\nhistory = model.fit(train_ds, epochs= CFG.epochs, steps_per_epoch=len(train_df) // CFG.batch_size,\n                    validation_data=valid_ds, validation_steps=len(valid_df) // CFG.batch_size,\n                    callbacks=[early_stopping])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = history.history\nx_arr = np.arange(len(hist['loss'])) + 1\n\nfig = plt.figure(figsize=(12, 4))\nax = fig.add_subplot(1, 2, 1)\nax.plot(x_arr, hist['loss'], '-o', label='Train loss')\nax.plot(x_arr, hist['val_loss'], '--<', label='Validation loss')\nax.legend(fontsize=15)\nax.set_xlabel('Epoch', size=15)\nax.set_ylabel('Loss', size=15)\n\nax = fig.add_subplot(1, 2, 2)\nax.plot(x_arr, hist['accuracy'], '-o', label='Train acc.')\nax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation acc.')\nax.legend(fontsize=15)\nax.set_xlabel('Epoch', size=15)\nax.set_ylabel('Accuracy', size=15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Written answer*:\n\n| Trining accuracy | Validation accuracy |  kernel size |  strides | pool size  |  learning rate | optimizer  | brightness (delta) |  contrast factor | flip_on_train  |\n|:-:                |:-:                  |:-:           |:-:       |:-:         |:-:              |:-:         |:-:                 |:-:               |:-:             |\n| 0.75              | 0.82                | 5,5          | 1,1      | 2,2        | 0.001          | Adam       | 0.3                | 3                | yes            |\n| 0.77               | 0.92                 | <font color=\"red\">3,3</font>     | 1,1      | 2,2        | 0.001          | Adam       | 0.3                | 3                | yes            |\n| 0.0               | 0.0                 | 5,5          | <font color=\"red\">2,2</font>  | 2,2        | 0.001          | Adam       | 0.3                | 3                | yes            |\n| 0.0               | 0.0                 | 5,5          | 1,1      | <font color=\"red\">3,3</font>   | 0.001          | Adam       | 0.3                | 3                | yes            |\n| 0.0               | 0.0                 | 5,5          | 1,1      | 2,2        | <font color=\"red\">0.01</font>       | Adam       | 0.3                | 3                | yes            |\n| 0.79               | 0.92                 | 5,5          | 1,1      | 2,2        | 0.001          |<font color=\"red\">SGD</font>     | 0.3                | 3                | yes            |\n| 0.0               | 0.0                 | 5,5          | 1,1      | 2,2        | 0.001          | Adam       | <font color=\"red\">0.1</font>            | 3                | yes            |\n| 0.0               | 0.0                 | 5,5          | 1,1      | 2,2        | 0.001          | Adam       | 0.3                | <font color=\"red\">2</font>            | yes            |\n| 0.0               | 0.0                 | 5,5          | 1,1      | 2,2        | 0.001          | Adam       | 0.3                | 3                | <font color=\"red\">no</font>         |\n\n\n","metadata":{}}]}